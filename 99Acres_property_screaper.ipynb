{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a20f1497-c570-4daf-b870-f18d99eb67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7183cb1e-1cbc-4c57-b456-7748649d94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProprertyScraper:\n",
    "\tdef __init__(self, url, timeout=5):\n",
    "\t\tself.url = url\n",
    "\t\tself.data = []\n",
    "\t\tself.driver = self._initialize_driver()\n",
    "\t\tself.wait = WebDriverWait(self.driver, timeout=timeout)\n",
    "\n",
    "\n",
    "\tdef _initialize_driver(self):\n",
    "\t\tchrome_options = Options()\n",
    "\t\tchrome_options.add_argument(\"--disable-http2\")\n",
    "\t\tchrome_options.add_argument(\"--incognito\")\n",
    "\t\tchrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\t\tchrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "\t\tchrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")\n",
    "\t\tchrome_options.add_argument(\"--disable-features=NetworkService\")\n",
    "\t\tchrome_options.add_argument(\n",
    "\t\t    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"\n",
    "\t\t)\n",
    "\t\tdriver = webdriver.Chrome(options=chrome_options)\n",
    "\t\tdriver.maximize_window()\n",
    "\t\treturn driver\n",
    "\n",
    "\n",
    "\tdef _wait_for_page_to_load(self):\n",
    "\t\ttitle = self.driver.title\n",
    "\t\ttry:\n",
    "\t\t\tself.wait.until(\n",
    "\t\t\t\tlambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "\t\t\t)\n",
    "\t\texcept:\n",
    "\t\t\tprint(f\"The webpage \\\"{title}\\\" did not get fully laoded.\\n\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"The webpage \\\"{title}\\\" did get fully laoded.\\n\")\n",
    "\n",
    "\t\n",
    "\tdef access_website(self):\n",
    "\t\tself.driver.get(self.url)\n",
    "\t\tself._wait_for_page_to_load()\n",
    "\n",
    "\n",
    "\tdef search_properties(self, text):\n",
    "\t\t# locating and entering text in search bar\n",
    "\t\ttry:\n",
    "\t\t\tsearch_bar = self.wait.until(\n",
    "\t\t\t\tEC.presence_of_element_located((By.XPATH, '//*[@id=\"keyword2\"]'))\n",
    "\t\t\t)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Timeout while locating Search Bar.\\n\")\n",
    "\t\telse:\n",
    "\t\t\tsearch_bar.send_keys(text)\n",
    "\t\t\ttime.sleep(2)\n",
    "\t\t\n",
    "\t\t# selecting valid option from list\n",
    "\t\ttry:\n",
    "\t\t\tvalid_option = self.wait.until(\n",
    "\t\t\t\tEC.element_to_be_clickable((By.XPATH, '//*[@id=\"0\"]'))\n",
    "\t\t\t)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Timeout while locating valid search option.\\n\")\n",
    "\t\telse:\n",
    "\t\t\tvalid_option.click()\n",
    "\t\t\ttime.sleep(2)\n",
    "\t\t\n",
    "\t\t# click on Search button\n",
    "\t\ttry:\n",
    "\t\t\tsearch_button = self.wait.until(\n",
    "\t\t\t\tEC.element_to_be_clickable((By.XPATH, '//*[@id=\"searchform_search_btn\"]'))\n",
    "\t\t\t)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Timeout while clicking on \\\"Search\\\" button.\\n\")\n",
    "\t\telse:\n",
    "\t\t\tsearch_button.click()\n",
    "\t\t\tself._wait_for_page_to_load()\n",
    "\n",
    "\n",
    "\tdef adjust_budget_slider(self, offset):\n",
    "\t\ttry:\n",
    "\t\t\tslider = self.wait.until(\n",
    "\t\t\t\tEC.element_to_be_clickable((By.XPATH, '//*[@id=\"budgetLeftFilter_max_node\"]'))\n",
    "\t\t\t)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Timeout while clicking on Budget slider circle.\\n\")\n",
    "\t\telse:\n",
    "\t\t\tactions = ActionChains(self.driver)\n",
    "\t\t\t(\n",
    "\t\t\t\tactions\n",
    "\t\t\t\t.click_and_hold(slider)\n",
    "\t\t\t\t.move_by_offset(offset, 0)\n",
    "\t\t\t\t.release()\n",
    "\t\t\t\t.perform()\n",
    "\t\t\t)\n",
    "\t\t\ttime.sleep(2)\n",
    "\n",
    "\n",
    "\tdef apply_filters(self):\n",
    "\t\t# 1. Verified\n",
    "\t\tverified = self.wait.until(\n",
    "\t\t\tEC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))\n",
    "\t\t)\n",
    "\t\tverified.click()\n",
    "\t\ttime.sleep(1)\n",
    "\t\t\n",
    "\t\t# 2. Ready To Move\n",
    "\t\tready_to_move = self.wait.until(\n",
    "\t\t\tEC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[5]/span[2]'))\n",
    "\t\t)\n",
    "\t\tready_to_move.click()\n",
    "\t\ttime.sleep(1)\n",
    "\t\t\n",
    "\t\t# moving to the right side to unhide remaining filters\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tfilter_right_button = self.wait.until(\n",
    "\t\t\t\t\tEC.presence_of_element_located((By.XPATH, \"//i[contains(@class,'iconS_Common_24 icon_upArrow cc__rightArrow')]\"))\n",
    "\t\t\t\t)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"Timeout because we have uncovered all filters.\\n\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tfilter_right_button.click()\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\t\n",
    "\t\t# 3. With Photos\n",
    "\t\twith_photos = self.wait.until(\n",
    "\t\t\tEC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[6]/span[2]'))\n",
    "\t\t)\n",
    "\t\twith_photos.click()\n",
    "\t\ttime.sleep(1)\n",
    "\t\t\n",
    "\t\t# 4. With Videos\n",
    "\t\twith_videos = self.wait.until(\n",
    "\t\t\tEC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[7]/span[2]'))\n",
    "\t\t)\n",
    "\t\twith_videos.click()\n",
    "\t\ttime.sleep(3)\n",
    "\n",
    "\n",
    "\tdef _extract_data(self, row, by, value):\n",
    "\t\ttry:\n",
    "\t\t\treturn row.find_element(by, value).text\n",
    "\t\texcept:\n",
    "\t\t\treturn np.nan\n",
    "\t\n",
    "\n",
    "\tdef scrape_webpage(self):\n",
    "\t\trows = self.driver.find_elements(By.CLASS_NAME, \"tupleNew__TupleContent\")\n",
    "\t\tfor row in rows:\n",
    "\t\t\tproperty = {\n",
    "\t\t\t\t\"name\": self._extract_data(row, By.CLASS_NAME, \"tupleNew__headingNrera\"),\n",
    "\t\t\t\t\"location\": self._extract_data(row, By.CLASS_NAME, \"tupleNew__propType\"),\n",
    "\t\t\t\t\"price\": self._extract_data(row, By.CLASS_NAME, \"tupleNew__priceValWrap\")\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\telements = row.find_elements(By.CLASS_NAME, \"tupleNew__area1Type\")\n",
    "\t\t\texcept:\n",
    "\t\t\t\tproperty[\"area\"], property[\"bhk\"] = [np.nan, np.nan]\n",
    "\t\t\telse:\n",
    "\t\t\t\tproperty[\"area\"], property[\"bhk\"] = [ele.text for ele in elements]\n",
    "\t\t\t\t\n",
    "\t\t\tself.data.append(property)\n",
    "\t\t\n",
    "\n",
    "\tdef navigate_pages_and_scrape_data(self):\n",
    "\t\tpage_count = 0\n",
    "\t\twhile True:\n",
    "\t\t\tpage_count += 1\n",
    "\t\t\ttry:\n",
    "\t\t\t\tself.scrape_webpage()\n",
    "\t\t\t\tnext_page_button = self.driver.find_element(By.XPATH, \"//a[normalize-space()='Next Page >']\")\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(f\"We have scraped {page_count} pages.\\n\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tself.driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)\n",
    "\t\t\t\t\ttime.sleep(2)\t\t\t\n",
    "\t\t\t\t\tself.wait.until(\n",
    "\t\t\t\t\t\tEC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page >']\"))\n",
    "\t\t\t\t\t).click()\n",
    "\t\t\t\t\ttime.sleep(10)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tprint(\"Timeout while clicking on \\\"Next Page\\\".\\n\")\n",
    "\n",
    "\n",
    "\tdef clean_data_and_save_as_excel(self, file_name):\n",
    "\t\tdf_properties = (\n",
    "\t\t\tpd\n",
    "\t\t\t.DataFrame(self.data)\n",
    "\t\t\t.drop_duplicates()\n",
    "\t\t\t.apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)\n",
    "\t\t\t.assign(\n",
    "\t\t\t\tis_starred=lambda df_: df_.name.str.contains(\"\\n\").astype(int),\n",
    "\t\t\t\tname=lambda df_: (\n",
    "\t\t\t\t\tdf_\n",
    "\t\t\t\t\t.name\n",
    "\t\t\t\t\t.str.replace(\"\\n[0-9.]+\", \"\", regex=True)\n",
    "\t\t\t\t\t.str.strip()\n",
    "\t\t\t\t\t.replace(\"adroit district s\", \"adroit district's\")\n",
    "\t\t\t\t),\n",
    "\t\t\t\tlocation=lambda df_: (\n",
    "\t\t\t\t\tdf_\n",
    "\t\t\t\t\t.location\n",
    "\t\t\t\t\t.str.replace(\"chennai\", \"\")\n",
    "\t\t\t\t\t.str.strip()\n",
    "\t\t\t\t\t.str.replace(\",$\", \"\", regex=True)\n",
    "\t\t\t\t\t.str.split(\"in\")\n",
    "\t\t\t\t\t.str[-1]\n",
    "\t\t\t\t\t.str.strip()\n",
    "\t\t\t\t),\n",
    "\t\t\t\tprice=lambda df_: (\n",
    "\t\t\t\t\tdf_\n",
    "\t\t\t\t\t.price\n",
    "\t\t\t\t\t.str.replace(\"â‚¹\", \"\")\n",
    "\t\t\t\t\t.apply(lambda val: float(val.replace(\"lac\", \"\").strip()) if \"lac\" in val else float(val.replace(\"cr\", \"\").strip()) * 100)\n",
    "\t\t\t\t),\n",
    "\t\t\t\tarea=lambda df_: (\n",
    "\t\t\t\t\tdf_\n",
    "\t\t\t\t\t.area\n",
    "\t\t\t\t\t.str.replace(\"sqft\", \"\")\n",
    "\t\t\t\t\t.str.strip()\n",
    "\t\t\t\t\t.str.replace(\",\", \"\")\n",
    "\t\t\t\t\t.pipe(lambda ser: pd.to_numeric(ser))\n",
    "\t\t\t\t),\n",
    "\t\t\t\tbhk=lambda df_: (\n",
    "\t\t\t\t\tdf_\n",
    "\t\t\t\t\t.bhk\n",
    "\t\t\t\t\t.str.replace(\"bhk\", \"\")\n",
    "\t\t\t\t\t.str.strip()\n",
    "\t\t\t\t\t.pipe(lambda ser: pd.to_numeric(ser))\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t\t.rename(columns={\n",
    "\t\t\t\t\"price\": \"price_lakhs\",\n",
    "\t\t\t\t\"area\": \"area_sqft\"\n",
    "\t\t\t})\n",
    "\t\t\t.reset_index(drop=True)\n",
    "\t\t)\n",
    "\t\tdf_properties.to_excel(f\"{file_name}.xlsx\", index=False)\n",
    "\n",
    "\t\n",
    "\tdef run(self, text=\"Chennai\", offset=-100, file_name=\"properties\"):\n",
    "\t\ttry:\n",
    "\t\t\tself.access_website()\n",
    "\t\t\tself.search_properties(text)\n",
    "\t\t\tself.adjust_budget_slider(offset)\n",
    "\t\t\tself.apply_filters()\n",
    "\t\t\tself.navigate_pages_and_scrape_data()\n",
    "\t\t\tself.clean_data_and_save_as_excel(file_name)\n",
    "\t\tfinally:\n",
    "\t\t\ttime.sleep(2)\n",
    "\t\t\tself.driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4da50548-2286-48c0-b319-133fcc041e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The webpage \"India Real Estate Property Site - Buy Sell Rent Properties Portal - 99acres.com\" did get fully laoded.\n",
      "\n",
      "The webpage \"Property in Chennai - Real Estate in Chennai\" did get fully laoded.\n",
      "\n",
      "Timeout because we have uncovered all filters.\n",
      "\n",
      "We have scraped 54 pages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tscraper = ProprertyScraper(url=\"https://www.99acres.com/\")\n",
    "\tscraper.run(\n",
    "\t\ttext=\"chennai\",\n",
    "\t\toffset=-73,\n",
    "\t\tfile_name=\"chennai-properties\"\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee66b5-472d-4a5d-a99b-60bc5654bd52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "web_scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
