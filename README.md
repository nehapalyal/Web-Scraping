PROJECT 1 : 

ğŸ“Š Yahoo Finance Stock Scraper
This project is a Python-based web scraper that uses Selenium to extract stock data from Yahoo Finance, focusing on the Most Active Stocks section.

ğŸš€ Features
Automatically navigates to the "Most Active Stocks" page on Yahoo Finance

1. Scrapes data such as:

  Stock Name & Symbol ,
  Price (USD) ,
  Daily Change , 
  Volume (in millions) ,
  Market Cap (converted to billions) ,
  PE Ratio 

2. Cleans and saves the data into an Excel file

ğŸ› ï¸ Tech Stack
   1. Python
   2. Selenium WebDriver
   3. Pandas, NumPy
   4. Excel export using openpyxl

ğŸ“‚ Output : An Excel file named Reconstructed yahoo scraper.xlsx containing structured stock data.



PROJECT 2 :

# ğŸ™ï¸ 99acres Real Estate Scraper

> A personal side project that tested my patienceâ€”and my Selenium skills! ğŸ˜…

This project scrapes real estate property listings from [99acres.com](https://www.99acres.com) using Selenium and filters them based on specific, real-world criteria. After collecting the data, I cleaned and organized it into a structured Excel file using Python and Pandas.

---

## ğŸ“Œ What I Scraped

The scraper targets listings that meet the following filters:

- ğŸ’° **Price:** Below â‚¹5 Crore  
- ğŸ  **Status:** Ready to move  
- âœ… **Verified:** Only verified properties  
- ğŸ¥ **Media:** Listings with both videos and photos  
- ğŸ“„ **Pagination:** Handled multiple pages with 'Next' button clicks

---

## ğŸ› ï¸ Tools & Technologies

- **Selenium** â€“ for automated browser control and interaction  
- **Pandas** â€“ for cleaning and organizing the data  
- **OpenPyXL / XlsxWriter** â€“ for Excel output (optional)  
- **ChromeDriver** â€“ to power Selenium with Chrome  
- **Time & Re module** â€“ for waits and text cleanup

---

## ğŸ§¹ Data Cleaning

Once scraped, the raw data was cleaned to remove:

- Duplicates  
- Incomplete entries  
- Extra whitespace or symbols  
- Inconsistent formatting in price, area, etc.

The cleaned dataset is saved as an Excel file (`99acres_cleaned_data.xlsx`), ready for further analysis or visualization.

---

## ğŸš€ Highlights & Challenges

- Automating slider filters and status dropdowns took a fair bit of trial and error ğŸ¯  
- Dealing with dynamic content and pagination meant building smart, repeatable navigation logic ğŸ§   
- Ensuring anti-bot measures didnâ€™t block me (hello, headless Chrome and wait tricks! ğŸ‘€)

---

## ğŸ“Š Sample Output

The final Excel file contains structured columns like:

- Property name 
- Price  
- Area (sq. ft)  
- Location  

---

## ğŸ™Œ Final Thoughts

This project was both a brain teaser and a patience workoutâ€”but totally worth it! Looking forward to exploring more automation, scraping, and data wrangling challenges.


âœ¨ Author
  Neha Palyal
